_wandb:
    value:
        cli_version: 0.19.1
        m: []
        python_version: 3.10.13
        t:
            "1":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 53
                - 55
                - 71
                - 98
            "2":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 53
                - 55
                - 71
                - 98
            "3":
                - 13
                - 16
                - 23
                - 55
            "4": 3.10.13
            "5": 0.19.1
            "6": 4.47.0
            "8":
                - 2
                - 5
            "12": 0.19.1
            "13": linux-x86_64
act2cap_data:
    value: hf_train
aitw_data:
    value: hf_train
aitz_data:
    value: hf_train
amex_data:
    value: hf_train
amexcap_data:
    value: hf_train_cap
assistgui_data:
    value: hf_train_full
attn_imple:
    value: sdpa
auto_resume:
    value: true
batch_size:
    value: 1
bbox2text:
    value: 0
beta1:
    value: 0.9
beta2:
    value: 0.95
crop_max:
    value: 1.5
crop_min:
    value: 0.5
dataset:
    value: showui
dataset_dir:
    value: $_DATA_DIR
debug:
    value: false
decay_factor:
    value: 1
distributed:
    value: false
draw_history:
    value: 0
ds_zero:
    value: zero2
epochs:
    value: 50
eval_only:
    value: false
exp_id:
    value: showui_desktop
frame_sampling:
    value: uniform
freeze_lm_embed:
    value: false
global_rank:
    value: 0
grad_accumulation_steps:
    value: 2
gradient_checkpointing:
    value: true
guiact_data:
    value: hf_train_web-single_v2
guiact_g_data:
    value: hf_train_web-single_ground
guichat_data:
    value: hf_train
guienv_data:
    value: hf_train
guiexp_data:
    value: hf_train_ground
guiexpweb_data:
    value: hf_train_v1
guiworld_data:
    value: hf_train
interleaved_history:
    value: tttt
layer_skip_rand:
    value: false
layer_skip_ratio:
    value: 0
layer_skip_type:
    value: '[1,28,0]'
liger_kernel:
    value: false
llava_data:
    value: llava_v1_5_mix665k
load_in_4bit:
    value: false
load_in_8bit:
    value: false
local_rank:
    value: 0
local_weight:
    value: false
local_weight_dir:
    value: .
log_base_dir:
    value: $_SAVE_DIR
log_dir:
    value: $_SAVE_DIR/showui_desktop/2025-01-01_06-18-03
lora_alpha:
    value: 64
lora_dropout:
    value: 0.05
lora_r:
    value: 32
lora_target_modules:
    value: qkv_proj
lr:
    value: 0.0001
max_frames:
    value: 16
max_new_tokens:
    value: 128
max_visual_tokens:
    value: 1344
merge_inference:
    value: false
merge_patch:
    value: 0
merge_pre_assign:
    value: false
merge_random:
    value: null
merge_style:
    value: s0
merge_threshold:
    value: 0
min_visual_tokens:
    value: 256
mind2web_data:
    value: hf_train
miniwob_data:
    value: hf_train
model_id:
    value: Qwen/Qwen2-VL-2B-Instruct
model_max_length:
    value: 4096
no_eval:
    value: false
num_crops:
    value: 16
num_frames:
    value: 1
num_history:
    value: 4
num_turn:
    value: 100
num_zoom_in:
    value: 0
odyssey_data:
    value: hf_train_random
omniact_data:
    value: hf_train_showui_desktop
omniact_nav_data:
    value: hf_train
osatlas_data:
    value: hf_desktop
point2text:
    value: 0
precision:
    value: bf16
print_freq:
    value: 1
prob_cap:
    value: 1
prob_plan:
    value: 0
prob_res:
    value: 1
prob_think:
    value: 1
random_sample:
    value: true
record_sample:
    value: true
resume:
    value: ""
ricosca_data:
    value: hf_train_ricosca
sample_rates:
    value: "1"
screencap_data:
    value: hf_train_screencap
seeclick_data:
    value: hf_train
showui_data:
    value: hf_train
shuffle_image_token:
    value: false
skip_readme_test:
    value: false
skip_readme_train:
    value: false
start_epoch:
    value: 0
steps_per_epoch:
    value: 100
synthesis_data:
    value: hf_train_10k
text2bbox:
    value: 0
text2point:
    value: 1
tmp_dir:
    value: $_SAVE_DIR/showui_desktop/2025-01-01_06-18-03/tmp
tune_visual_encoder:
    value: false
tune_visual_encoder_projector:
    value: false
uniform_prompt:
    value: true
uniform_sample:
    value: false
use_qlora:
    value: false
val_aitw_data:
    value: hf_test
val_aitz_data:
    value: hf_test
val_batch_size:
    value: 1
val_dataset:
    value: screenspot
val_guiact_data:
    value: hf_test_web-single
val_guiworld_data:
    value: hf_test_mcq
val_mind2web_data:
    value: hf_test_full
val_odyssey_data:
    value: hf_test_random
val_omniact_nav_data:
    value: hf_test
val_sample_rates:
    value: "1"
val_screenspot_data:
    value: hf_test_full
version:
    value: Qwen/Qwen2-VL-2B-Instruct
vis_layer_skip_keep:
    value: false
vis_layer_skip_ratio:
    value: 0
vis_layer_skip_type:
    value: '[1,32,0]'
wandb_key:
    value: d07e0f4987739744a31c4d35085706f4276df4f4
warmup_steps:
    value: 100
warmup_type:
    value: linear
widget_data:
    value: hf_train_widget
workers:
    value: 4
world_size:
    value: 1
xlam_data:
    value: hf_train
xy_int:
    value: false
